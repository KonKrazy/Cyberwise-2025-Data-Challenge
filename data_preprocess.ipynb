{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbf0e3e",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb65a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import io\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from os import path\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a064f73",
   "metadata": {},
   "source": [
    "## Step 2: Load the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d7661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset (which excludes Backdoor activity)\n",
    "df = pd.read_csv(\"EVSE-B-HPC-Kernel-Events-cleaned.csv\", low_memory=False)\n",
    "\n",
    "# Load the Backdoor activity dataset separately\n",
    "dfb = pd.read_csv(\"backdoors.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19d570",
   "metadata": {},
   "source": [
    "## Step 3: Define Kernel Events of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4021e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of kernel events we want to analyze\n",
    "kernel_events = [\n",
    "    \"instructions\", \"cpu-migrations\", \"mem_access_rd\", \"mem_access_wr\", \n",
    "    \"cache-misses\", \"L1-icache-loads\", \"dTLB-store-misses\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e8a98",
   "metadata": {},
   "source": [
    "## Step 4: Identify Overlapping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a17a62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping kernel events: ['instructions', 'cpu-migrations', 'mem_access_rd', 'mem_access_wr', 'cache-misses', 'L1-icache-loads', 'dTLB-store-misses']\n",
      "Number of overlapping events: 7\n"
     ]
    }
   ],
   "source": [
    "# Find common kernel events between both datasets\n",
    "df_columns = set(df.columns)\n",
    "dfb_columns = set(dfb.columns)\n",
    "overlapping_events = [event for event in kernel_events if event in df_columns and event in dfb_columns]\n",
    "\n",
    "# Display overlapping kernel events\n",
    "print(\"Overlapping kernel events:\", overlapping_events)\n",
    "print(\"Number of overlapping events:\", len(overlapping_events))\n",
    "\n",
    "# Raise an error if no overlapping events are found\n",
    "if not overlapping_events:\n",
    "    raise ValueError(\"No overlapping kernel events found between the two datasets. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a3168",
   "metadata": {},
   "source": [
    "## Step 5: Ensure Numeric Columns for Kernel Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5337e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert kernel event columns to numeric, coercing errors to NaN\n",
    "for event in overlapping_events:\n",
    "    df[event] = pd.to_numeric(df[event], errors='coerce')\n",
    "    dfb[event] = pd.to_numeric(dfb[event], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d7c7e",
   "metadata": {},
   "source": [
    "## Step 6: Assign Labels for Backdoor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d84338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Scenario\" column is missing in dfb, so we manually assign \"Backdoor\" to all rows\n",
    "dfb[\"Scenario\"] = \"Backdoor\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7651ef3",
   "metadata": {},
   "source": [
    "## Step 7: Select Relevant Columns for Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f325dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns for both datasets\n",
    "df_cols_to_keep = overlapping_events + [\"Scenario\", \"msec\"]\n",
    "dfb_cols_to_keep = overlapping_events + [\"Scenario\", \"msec\"]\n",
    "df = df[df_cols_to_keep]\n",
    "dfb = dfb[dfb_cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a201e",
   "metadata": {},
   "source": [
    "## Step 8: Merge the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0422c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both datasets into a single DataFrame\n",
    "df_combined = pd.concat([df, dfb], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cdcf05",
   "metadata": {},
   "source": [
    "## Step 9: Sort Data by Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba38c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by 'msec' to maintain chronological order\n",
    "df_combined = df_combined.sort_values(\"msec\")\n",
    "df_combined[\"sample_index\"] = range(len(df_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554b36c",
   "metadata": {},
   "source": [
    "## Step 10: Convert Scenarios into Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3594118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all non-benign scenarios to \"Attack\"\n",
    "df_combined[\"Scenario\"] = df_combined[\"Scenario\"].apply(lambda x: \"Attack\" if x != \"Benign\" else \"Benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5c340",
   "metadata": {},
   "source": [
    "## Step 11: Create Feature DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cdf0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new DataFrame for model training\n",
    "feature_data = pd.DataFrame()\n",
    "feature_data[\"sample_index\"] = df_combined[\"sample_index\"]\n",
    "feature_data[\"Scenario\"] = df_combined[\"Scenario\"]  # Binary classification target\n",
    "\n",
    "# Add raw kernel event data (no statistical computations)\n",
    "for event in overlapping_events:\n",
    "    feature_data[event] = df_combined[event]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3d57c",
   "metadata": {},
   "source": [
    "## Step 12: Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b139c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 to ensure model compatibility\n",
    "feature_data = feature_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320547e",
   "metadata": {},
   "source": [
    "## Step 13: Display Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5b27023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature DataFrame (first 5 rows):\n",
      "      sample_index Scenario  instructions  cpu-migrations  mem_access_rd  \\\n",
      "5005             0   Attack  4.842734e+08             0.0    182447274.0   \n",
      "4330             1   Attack  3.360893e+08             0.0     83614575.0   \n",
      "5059             2   Attack  2.504586e+08             0.0     62673568.0   \n",
      "5121             3   Attack  3.815842e+08             0.0     61085549.0   \n",
      "4695             4   Attack  2.012276e+09             0.0    464448105.0   \n",
      "\n",
      "      mem_access_wr  cache-misses  L1-icache-loads  dTLB-store-misses  \n",
      "5005    157319220.0     2113406.0      245241558.0           127193.0  \n",
      "4330     51690301.0     1521862.0      213434196.0           161965.0  \n",
      "5059    123802350.0     1212126.0       69182309.0            18750.0  \n",
      "5121     49477220.0      681121.0      158026571.0           226431.0  \n",
      "4695    344314102.0    11346447.0      943011302.0           776176.0  \n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the processed feature DataFrame\n",
    "print(\"\\nFeature DataFrame (first 5 rows):\")\n",
    "print(feature_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc275d35",
   "metadata": {},
   "source": [
    "## Step 14: Save Processed Features to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature dataset to a CSV file for model training\n",
    "feature_data.to_csv(\"evse_features.csv\", index=False)\n",
    "print(\"\\nFeatures saved to 'evse_features.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
